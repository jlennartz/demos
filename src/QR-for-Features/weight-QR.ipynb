{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1a365b0-3886-4bc3-a306-caa4db02262b",
   "metadata": {},
   "source": [
    "### Small example illustrating:  \n",
    "1. the similarity between 1x1 convolutions and fully connected layers  \n",
    "2. the application of the QR decomposition to decompose inputs (i.e. features) into class specific and non-class specific features in cases where the 1x1 convolution is the final layer for e.g. a segmentation task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "26ffd8d0-dd7b-4a29-8856-9642888cf93e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "11804567-df9c-414d-953d-84b32e23f8e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    \"\"\"single layer 1x1 conv network with additional\n",
    "    fc layer with similar param space.\n",
    "    \n",
    "    Match params of both modules by calling params_conv2fc.\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels=20, out_channels=5):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv = nn.Conv2d(\n",
    "            in_channels=in_channels, \n",
    "            out_channels=out_channels, \n",
    "            kernel_size=1\n",
    "        )\n",
    "        \n",
    "        self.fc = nn.Linear(\n",
    "            in_features=in_channels,\n",
    "            out_features=out_channels\n",
    "        )\n",
    "        \n",
    "        \n",
    "    def params_conv2fc(self):\n",
    "        self.fc.weight.data = self.conv.weight.data.squeeze()\n",
    "        self.fc.bias.data   = self.conv.bias.data\n",
    "        \n",
    "    def forward(self, x, mode='conv'):\n",
    "        if mode == 'conv':\n",
    "            return self.conv(x)\n",
    "        elif mode == 'fc':\n",
    "            # move channel to last\n",
    "            x = x.movedim(1, 3)\n",
    "            # apply fc layer\n",
    "            x = self.fc(x)\n",
    "            # move channel to second position to match conv layer\n",
    "            return x.movedim(3, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "04dc3a8d-67fd-4fc7-a73e-6e31ad5e12a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### - Verify that 1x1 conv is interchangable with fc layer\n",
    "# init model and test input\n",
    "model = Network()\n",
    "#                   B,  C, H, W\n",
    "x_in  = torch.ones((4, 20, 2, 2))\n",
    "# match functions by copying conv params to fc layer\n",
    "model.params_conv2fc()\n",
    "# test if all close\n",
    "torch.allclose(model(x_in, mode='conv'), model(x_in, mode='fc'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "648612dc-f5d8-4936-81da-b92e7c461a39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input feature shape (with bias):  torch.Size([100, 21])\n",
      "Shape of class specific features: torch.Size([100, 5])\n",
      "Shape of class specific features: torch.Size([100, 16])\n"
     ]
    }
   ],
   "source": [
    "### Extract weights and perform QR decomposition\n",
    "# weights composed of weight and bias scalars. Later, we need to\n",
    "# make sure to add a 1 as last channel when multiplying with Q.\n",
    "# Consider, that our feature vectors are of shape (-1, C) in \n",
    "# our particular use case. Adapt accordingly\n",
    "\n",
    "# shape (C, n_classes)\n",
    "W = torch.cat(\n",
    "    [\n",
    "        model.conv.weight.data.squeeze(), \n",
    "        model.conv.bias.data.unsqueeze(1)\n",
    "    ],\n",
    "    dim=1\n",
    ").T\n",
    "# apply QR decomp\n",
    "Q, R = torch.linalg.qr(W, mode='complete')\n",
    "# init input features\n",
    "x = torch.ones((100, 20))\n",
    "# add bias term\n",
    "x = torch.cat([x, torch.ones((100, 1))], dim=1)\n",
    "print(f\"Input feature shape (with bias):  {x.shape}\")\n",
    "# project all inputs onto used subspace\n",
    "truncated_features = x @ Q[:,  :5]\n",
    "# remaining features are slightly weird, b/c of bias term.\n",
    "# Technically, it counts towards the features\n",
    "remaining_features = x @ Q[:, 5:]\n",
    "print(f\"Shape of class specific features: {truncated_features.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe5e00f-041d-4458-bf33-07c846f5dd8c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
